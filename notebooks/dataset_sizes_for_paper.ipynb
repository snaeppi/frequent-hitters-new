{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c91cde6",
   "metadata": {},
   "source": [
    "# Dataset size summaries for frequent-hitters\n",
    "\n",
    "This notebook computes dataset sizes and filtering statistics used in the paper based on the current assay-cleaning + dataset pipeline outputs. Paths point at the raw HTS inputs, cleaned parquet files, and the four processed model-ready datasets, and we include a quick split-consistency check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9d0d5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polars version: 1.35.2\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from typing import Optional, Tuple, Dict\n",
    "import json\n",
    "\n",
    "import polars as pl\n",
    "from rdkit import Chem, RDLogger\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem.MolStandardize import rdMolStandardize\n",
    "\n",
    "# Silence RDKit warnings\n",
    "RDLogger.logger().setLevel(RDLogger.CRITICAL)\n",
    "\n",
    "# Show Polars version for reproducibility\n",
    "print(\"Polars version:\", pl.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed4e30e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assay tables dir: /Users/snappi/frequent-hitters/assay-etl/data/assay_tables\n",
      "Assay metadata: /Users/snappi/frequent-hitters/assay-etl/outputs/assay_metadata.csv\n",
      "Assay rscores: /Users/snappi/frequent-hitters/assay-etl/outputs/assay_rscores.parquet\n",
      "Assay-cleaning stats: /Users/snappi/frequent-hitters/data/clean/assay_cleaning_stats.json\n",
      "Clean biochemical path: /Users/snappi/frequent-hitters/data/clean/biochemical.parquet\n",
      "Clean cellular path: /Users/snappi/frequent-hitters/data/clean/cellular.parquet\n",
      "Processed outputs:\n",
      "  biochemical_regression: /Users/snappi/frequent-hitters/data/processed50/biochemical/biochemical_regression.parquet\n",
      "  biochemical_multilabel: /Users/snappi/frequent-hitters/data/processed50/biochemical/biochemical_multilabel.parquet\n",
      "  cellular_regression: /Users/snappi/frequent-hitters/data/processed50/cellular/cellular_regression.parquet\n",
      "  cellular_multilabel: /Users/snappi/frequent-hitters/data/processed50/cellular/cellular_multilabel.parquet\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Adjust these paths if you run the notebook from a different working directory.\n",
    "project_root = Path.cwd().parent\n",
    "\n",
    "assay_tables_dir = project_root / \"assay-etl\" / \"data\" / \"assay_tables\"\n",
    "assay_metadata_path = project_root / \"assay-etl\" / \"outputs\" / \"assay_metadata.csv\"\n",
    "assay_rscores_path = project_root / \"assay-etl\" / \"outputs\" / \"assay_rscores.parquet\"\n",
    "assay_cleaning_stats_path = project_root / \"data\" / \"clean\" / \"assay_cleaning_stats.json\"\n",
    "\n",
    "# Paths to assay-cleaning outputs for the full dataset.\n",
    "clean_biochemical_path = project_root / \"data\" / \"clean\" / \"biochemical.parquet\"\n",
    "clean_cellular_path = project_root / \"data\" / \"clean\" / \"cellular.parquet\"\n",
    "\n",
    "# Final processed dataset locations (one parquet per assay format and model type).\n",
    "processed_dir = project_root / \"data\" / \"processed50\"\n",
    "processed_paths = {\n",
    "    \"biochemical_regression\": processed_dir / \"biochemical\" / \"biochemical_regression.parquet\",\n",
    "    \"biochemical_multilabel\": processed_dir / \"biochemical\" / \"biochemical_multilabel.parquet\",\n",
    "    \"cellular_regression\": processed_dir / \"cellular\" / \"cellular_regression.parquet\",\n",
    "    \"cellular_multilabel\": processed_dir / \"cellular\" / \"cellular_multilabel.parquet\",\n",
    "}\n",
    "scaffold_assignments_path = processed_dir / \"scaffold_assignments.parquet\"\n",
    "\n",
    "print(\"Assay tables dir:\", assay_tables_dir)\n",
    "print(\"Assay metadata:\", assay_metadata_path)\n",
    "print(\"Assay rscores:\", assay_rscores_path)\n",
    "print(\"Assay-cleaning stats:\", assay_cleaning_stats_path)\n",
    "print(\"Clean biochemical path:\", clean_biochemical_path)\n",
    "print(\"Clean cellular path:\", clean_cellular_path)\n",
    "print(\"Processed outputs:\")\n",
    "for name, path in processed_paths.items():\n",
    "    print(f\"  {name}: {path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243eced0",
   "metadata": {},
   "source": [
    "## 1. Assays with ≥10k substances and unique compounds\n",
    "\n",
    "Counts based on the pre-filtered assay tables in `assay-etl/data/assay_tables`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9d6be13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of assays with ≥10k substances (assay tables): 1323\n",
      "Example columns (first assay table): ['PUBCHEM_CID', 'PUBCHEM_RESULT_TAG', 'PUBCHEM_ACTIVITY_SCORE', 'LogGI50_M', 'LogGI50_u', 'LogGI50_V', 'IndnGI50', 'StddevGI50', 'LogTGI_M', 'LogTGI_u', 'LogTGI_V', 'IndnTGI', 'StddevTGI', 'PUBCHEM_EXT_DATASOURCE_SMILES', 'PUBCHEM_ACTIVITY_OUTCOME', '_LogGI50_mean', '_LogTGI_mean']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>num_rows</th><th>num_unique_compounds</th></tr><tr><td>u32</td><td>u32</td></tr></thead><tbody><tr><td>243047406</td><td>2955548</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 2)\n",
       "┌───────────┬──────────────────────┐\n",
       "│ num_rows  ┆ num_unique_compounds │\n",
       "│ ---       ┆ ---                  │\n",
       "│ u32       ┆ u32                  │\n",
       "╞═══════════╪══════════════════════╡\n",
       "│ 243047406 ┆ 2955548              │\n",
       "└───────────┴──────────────────────┘"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# List assay table parquet files (each file corresponds to one assay with ≥10k substances).\n",
    "assay_table_files = sorted(assay_tables_dir.glob(\"aid_*.parquet\"))\n",
    "\n",
    "assay_table_df = pl.DataFrame(\n",
    "    {\n",
    "        \"assay_id\": [int(p.stem.split(\"_\")[1]) for p in assay_table_files],\n",
    "        \"path\": [str(p) for p in assay_table_files],\n",
    "    }\n",
    ")\n",
    "\n",
    "num_assays_ge_10k = assay_table_df.height\n",
    "print(f\"Number of assays with ≥10k substances (assay tables): {num_assays_ge_10k}\")\n",
    "\n",
    "assay_level_stats = pl.DataFrame()\n",
    "\n",
    "if assay_table_files:\n",
    "    # Inspect the first file to infer column names.\n",
    "    first_schema_cols = pl.read_parquet(assay_table_files[0], n_rows=0).columns\n",
    "    print(\"Example columns (first assay table):\", first_schema_cols)\n",
    "\n",
    "    cid_candidates = [c for c in first_schema_cols if c.lower().endswith(\"cid\") or c.lower() == \"pubchem_cid\"]\n",
    "    sid_candidates = [c for c in first_schema_cols if c.lower().endswith(\"sid\") or c.lower() == \"pubchem_sid\"]\n",
    "\n",
    "    cid_col = cid_candidates[0] if cid_candidates else None\n",
    "    sid_col = sid_candidates[0] if sid_candidates else None\n",
    "\n",
    "    per_file_lfs = []\n",
    "    has_sid = False\n",
    "    for path in assay_table_files:\n",
    "        file_cols = pl.read_parquet(path, n_rows=0).columns\n",
    "        lf = pl.scan_parquet(path)\n",
    "        projections = []\n",
    "        if cid_col and cid_col in file_cols:\n",
    "            projections.append(pl.col(cid_col).cast(pl.Utf8).alias(\"_cid\"))\n",
    "        if sid_col and sid_col in file_cols:\n",
    "            projections.append(pl.col(sid_col).cast(pl.Utf8).alias(\"_sid\"))\n",
    "            has_sid = True\n",
    "        if not projections:\n",
    "            continue\n",
    "        per_file_lfs.append(lf.select(projections))\n",
    "\n",
    "    if per_file_lfs:\n",
    "        assay_tables_lf = pl.concat(per_file_lfs)\n",
    "\n",
    "        select_exprs = [pl.len().alias(\"num_rows\")]\n",
    "        if has_sid:\n",
    "            select_exprs.append(pl.col(\"_sid\").n_unique().alias(\"num_unique_substances\"))\n",
    "        if cid_col:\n",
    "            select_exprs.append(pl.col(\"_cid\").n_unique().alias(\"num_unique_compounds\"))\n",
    "\n",
    "        assay_level_stats = assay_tables_lf.select(select_exprs).collect(engine=\"streaming\")\n",
    "\n",
    "assay_level_stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639bf07f",
   "metadata": {},
   "source": [
    "## 2. Assay and compound counts after column selection\n",
    "\n",
    "Uses `assay_metadata.csv` to quantify how many assays/compounds are retained vs ineligible after selecting a single readout column.\n",
    "\n",
    "`compounds_screened` counts the number of compound–assay screening pairs (not unique compounds).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b71ba31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assay counts after column selection:\n",
      "Compound (screening) counts based on assay_metadata:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>num_assays</th><th>total_compounds_screened</th><th>compounds_screened_eligible</th><th>compounds_screened_ineligible</th></tr><tr><td>u32</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>1323</td><td>242970045</td><td>229726022</td><td>13244023</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 4)\n",
       "┌────────────┬──────────────────────────┬─────────────────────────────┬────────────────────────────┐\n",
       "│ num_assays ┆ total_compounds_screened ┆ compounds_screened_eligible ┆ compounds_screened_ineligi │\n",
       "│ ---        ┆ ---                      ┆ ---                         ┆ ble                        │\n",
       "│ u32        ┆ i64                      ┆ i64                         ┆ ---                        │\n",
       "│            ┆                          ┆                             ┆ i64                        │\n",
       "╞════════════╪══════════════════════════╪═════════════════════════════╪════════════════════════════╡\n",
       "│ 1323       ┆ 242970045                ┆ 229726022                   ┆ 13244023                   │\n",
       "└────────────┴──────────────────────────┴─────────────────────────────┴────────────────────────────┘"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assay_meta = pl.read_csv(assay_metadata_path, infer_schema_length=1000)\n",
    "\n",
    "total_assays = assay_meta.height\n",
    "num_ineligible_assays = assay_meta.filter(pl.col(\"selected_column\") == \"__INELIGIBLE__\").height\n",
    "num_eligible_assays = total_assays - num_ineligible_assays\n",
    "\n",
    "assay_selection_summary = pl.DataFrame(\n",
    "    {\n",
    "        \"total_assays\": [total_assays],\n",
    "        \"eligible_assays\": [num_eligible_assays],\n",
    "        \"ineligible_assays\": [num_ineligible_assays],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Assay counts after column selection:\")\n",
    "assay_selection_summary\n",
    "\n",
    "compound_selection_summary = assay_meta.select(\n",
    "    pl.len().alias(\"num_assays\"),\n",
    "    pl.col(\"compounds_screened\").sum().alias(\"total_compounds_screened\"),\n",
    "    pl.when(pl.col(\"selected_column\") != \"__INELIGIBLE__\")\n",
    "    .then(pl.col(\"compounds_screened\"))\n",
    "    .otherwise(0)\n",
    "    .sum()\n",
    "    .alias(\"compounds_screened_eligible\"),\n",
    "    pl.when(pl.col(\"selected_column\") == \"__INELIGIBLE__\")\n",
    "    .then(pl.col(\"compounds_screened\"))\n",
    "    .otherwise(0)\n",
    "    .sum()\n",
    "    .alias(\"compounds_screened_ineligible\"),\n",
    ")\n",
    "\n",
    "print(\"Compound (screening) counts based on assay_metadata:\")\n",
    "compound_selection_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec708d7a",
   "metadata": {},
   "source": [
    "## 3. Assay format breakdown (biochemical vs cellular vs other)\n",
    "\n",
    "Counts of assays by `assay_format` from `assay_metadata.csv`, before and after applying the column-selection eligibility filter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de7ea196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assay counts by format (all assays):\n",
      "shape: (4, 2)\n",
      "┌──────────────┬────────────┐\n",
      "│ assay_format ┆ num_assays │\n",
      "│ ---          ┆ ---        │\n",
      "│ str          ┆ u32        │\n",
      "╞══════════════╪════════════╡\n",
      "│ null         ┆ 94         │\n",
      "│ biochemical  ┆ 471        │\n",
      "│ cellular     ┆ 389        │\n",
      "│ other        ┆ 369        │\n",
      "└──────────────┴────────────┘\n",
      "\n",
      "Assay counts by format (eligible only):\n",
      "shape: (3, 2)\n",
      "┌──────────────┬─────────────────────┐\n",
      "│ assay_format ┆ num_assays_eligible │\n",
      "│ ---          ┆ ---                 │\n",
      "│ str          ┆ u32                 │\n",
      "╞══════════════╪═════════════════════╡\n",
      "│ biochemical  ┆ 455                 │\n",
      "│ cellular     ┆ 361                 │\n",
      "│ other        ┆ 289                 │\n",
      "└──────────────┴─────────────────────┘\n",
      "\n",
      "Assay counts by format (ineligible only):\n",
      "shape: (4, 2)\n",
      "┌──────────────┬───────────────────────┐\n",
      "│ assay_format ┆ num_assays_ineligible │\n",
      "│ ---          ┆ ---                   │\n",
      "│ str          ┆ u32                   │\n",
      "╞══════════════╪═══════════════════════╡\n",
      "│ null         ┆ 91                    │\n",
      "│ biochemical  ┆ 16                    │\n",
      "│ cellular     ┆ 27                    │\n",
      "│ other        ┆ 80                    │\n",
      "└──────────────┴───────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "assay_format_total = (\n",
    "    assay_meta\n",
    "    .group_by(\"assay_format\")\n",
    "    .agg(pl.len().alias(\"num_assays\"))\n",
    "    .sort(\"assay_format\")\n",
    ")\n",
    "\n",
    "assay_format_eligible = (\n",
    "    assay_meta\n",
    "    .filter(pl.col(\"selected_column\") != \"__INELIGIBLE__\")\n",
    "    .group_by(\"assay_format\")\n",
    "    .agg(pl.len().alias(\"num_assays_eligible\"))\n",
    "    .sort(\"assay_format\")\n",
    ")\n",
    "\n",
    "assay_format_ineligible = (\n",
    "    assay_meta\n",
    "    .filter(pl.col(\"selected_column\") == \"__INELIGIBLE__\")\n",
    "    .group_by(\"assay_format\")\n",
    "    .agg(pl.len().alias(\"num_assays_ineligible\"))\n",
    "    .sort(\"assay_format\")\n",
    ")\n",
    "\n",
    "print(\"Assay counts by format (all assays):\")\n",
    "print(assay_format_total)\n",
    "\n",
    "print(\"\\nAssay counts by format (eligible only):\")\n",
    "print(assay_format_eligible)\n",
    "\n",
    "print(\"\\nAssay counts by format (ineligible only):\")\n",
    "print(assay_format_ineligible)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00103c58",
   "metadata": {},
   "source": [
    "## 4. Overall impact of assay-cleaning on HTS data\n",
    "\n",
    "Summaries before/after cleaning using the full HTS hits table (`assay_rscores.parquet`) and the cleaned biochemical / cellular outputs in `data/clean`. With `assay_cleaning_stats.json` present, we load those stats instead of re-scanning the large parquet files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e34990d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assay-cleaning stats loaded from /Users/snappi/frequent-hitters/data/clean/assay_cleaning_stats.json\n",
      "Input summary:\n",
      "Cleaned output summary:\n",
      "Structure cleaning summary:\n",
      "Drop reasons (unique SMILES):\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Prefer precomputed stats from the cleaning run to avoid re-scanning 200M-row tables locally.\n",
    "if assay_cleaning_stats_path.is_file():\n",
    "    stats = json.loads(assay_cleaning_stats_path.read_text())\n",
    "\n",
    "    input_summary = pl.DataFrame([\n",
    "        {\"stage\": \"raw_input\", **stats[\"input\"]}\n",
    "    ])\n",
    "\n",
    "    clean_summary = pl.DataFrame(\n",
    "        [{\"stage\": f\"clean_{k}\", **v} for k, v in stats[\"output\"].items()]\n",
    "    )\n",
    "\n",
    "    drop_reason_rows = [\n",
    "        {\"reason\": reason, \"count\": count}\n",
    "        for reason, count in stats[\"structure_cleaning\"][\"drop_reasons\"].items()\n",
    "    ]\n",
    "    drop_reason_summary = pl.DataFrame(drop_reason_rows).sort(\"count\", descending=True)\n",
    "\n",
    "    print(\"Assay-cleaning stats loaded from\", assay_cleaning_stats_path)\n",
    "    print(\"Input summary:\")\n",
    "    input_summary\n",
    "    print(\"Cleaned output summary:\")\n",
    "    clean_summary\n",
    "    print(\"Structure cleaning summary:\")\n",
    "    pl.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"unique_smiles\": stats[\"structure_cleaning\"][\"unique_smiles\"],\n",
    "                \"valid_canonical_smiles\": stats[\"structure_cleaning\"][\"valid_canonical_smiles\"],\n",
    "                \"dropped\": stats[\"structure_cleaning\"][\"dropped\"],\n",
    "                \"skip_tautomers\": stats[\"structure_cleaning\"][\"skip_tautomers\"],\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    print(\"Drop reasons (unique SMILES):\")\n",
    "    drop_reason_summary\n",
    "else:\n",
    "    print(\"assay_cleaning_stats.json not found; computing summaries (expensive)...\")\n",
    "\n",
    "    # Summary of the raw HTS hits table used as input to assay-cleaning.\n",
    "    hts_lf = pl.scan_parquet(assay_rscores_path)\n",
    "\n",
    "    hts_summary = hts_lf.select(\n",
    "        pl.len().alias(\"num_rows\"),\n",
    "        pl.col(\"assay_id\").n_unique().alias(\"num_assays\"),\n",
    "        pl.col(\"compound_id\").n_unique().alias(\"num_unique_compounds\"),\n",
    "    ).collect()\n",
    "\n",
    "    print(\"Raw HTS hits (assay_rscores.parquet):\")\n",
    "    hts_summary\n",
    "\n",
    "    # Summaries for the cleaned biochemical / cellular outputs (if available).\n",
    "    clean_lfs = []\n",
    "    if clean_biochemical_path.is_file():\n",
    "        clean_lfs.append(pl.scan_parquet(str(clean_biochemical_path)))\n",
    "    if clean_cellular_path.is_file():\n",
    "        clean_lfs.append(pl.scan_parquet(str(clean_cellular_path)))\n",
    "\n",
    "    if clean_lfs:\n",
    "        clean_lf = clean_lfs[0]\n",
    "        for lf in clean_lfs[1:]:\n",
    "            clean_lf = clean_lf.union(lf)\n",
    "\n",
    "        clean_summary = clean_lf.select(\n",
    "            pl.len().alias(\"num_rows\"),\n",
    "            pl.col(\"assay_id\").n_unique().alias(\"num_assays\"),\n",
    "            pl.col(\"compound_id\").n_unique().alias(\"num_unique_compounds\"),\n",
    "        ).collect()\n",
    "\n",
    "        print(\"Cleaned HTS hits after assay-cleaning (combined biochemical + cellular):\")\n",
    "        clean_summary\n",
    "\n",
    "        pre_rows = int(hts_summary[\"num_rows\"][0])\n",
    "        pre_compounds = int(hts_summary[\"num_unique_compounds\"][0])\n",
    "        post_rows = int(clean_summary[\"num_rows\"][0])\n",
    "        post_compounds = int(clean_summary[\"num_unique_compounds\"][0])\n",
    "\n",
    "        drop_summary = pl.DataFrame(\n",
    "            {\n",
    "                \"num_rows_before\": [pre_rows],\n",
    "                \"num_rows_after\": [post_rows],\n",
    "                \"num_rows_dropped\": [pre_rows - post_rows],\n",
    "                \"num_unique_compounds_before\": [pre_compounds],\n",
    "                \"num_unique_compounds_after\": [post_compounds],\n",
    "                \"num_unique_compounds_dropped\": [pre_compounds - post_compounds],\n",
    "            }\n",
    "        )\n",
    "        print(\"Overall rows / unique-compound counts before vs after assay-cleaning:\")\n",
    "        drop_summary\n",
    "    else:\n",
    "        print(\n",
    "            \"Clean-split outputs not found at the configured paths; \"\n",
    "            \"skipping pre/post assay-cleaning summary.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b2ab55",
   "metadata": {},
   "source": [
    "## 5. Final processed datasets and split consistency\n",
    "\n",
    "Summaries for the four model-ready parquet files (biochemical vs cellular × regression vs multitask). Each file contains multiple split columns (`split1`, `split2`, …); the test compounds should match between regression and multitask datasets for a given seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69794dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed dataset overview:\n",
      "shape: (4, 7)\n",
      "┌──────────────┬──────────────┬──────────┬──────────────┬──────────────┬─────────────┬─────────────┐\n",
      "│ dataset      ┆ path         ┆ num_rows ┆ unique_compo ┆ unique_scaff ┆ num_assay_t ┆ split_colum │\n",
      "│ ---          ┆ ---          ┆ ---      ┆ unds         ┆ olds         ┆ asks        ┆ ns          │\n",
      "│ str          ┆ str          ┆ i64      ┆ ---          ┆ ---          ┆ ---         ┆ ---         │\n",
      "│              ┆              ┆          ┆ i64          ┆ i64          ┆ i64         ┆ str         │\n",
      "╞══════════════╪══════════════╪══════════╪══════════════╪══════════════╪═════════════╪═════════════╡\n",
      "│ biochemical_ ┆ /Users/snapp ┆ 368371   ┆ 368352       ┆ 103100       ┆ 444         ┆ split1,     │\n",
      "│ regression   ┆ i/frequent-h ┆          ┆              ┆              ┆             ┆ split2,     │\n",
      "│              ┆ itters…      ┆          ┆              ┆              ┆             ┆ split3,     │\n",
      "│              ┆              ┆          ┆              ┆              ┆             ┆ split4…     │\n",
      "│ biochemical_ ┆ /Users/snapp ┆ 1944299  ┆ 1944161      ┆ 547187       ┆ 444         ┆ split1,     │\n",
      "│ multilabel   ┆ i/frequent-h ┆          ┆              ┆              ┆             ┆ split2,     │\n",
      "│              ┆ itters…      ┆          ┆              ┆              ┆             ┆ split3,     │\n",
      "│              ┆              ┆          ┆              ┆              ┆             ┆ split4…     │\n",
      "│ cellular_reg ┆ /Users/snapp ┆ 365370   ┆ 365351       ┆ 102726       ┆ 329         ┆ split1,     │\n",
      "│ ression      ┆ i/frequent-h ┆          ┆              ┆              ┆             ┆ split2,     │\n",
      "│              ┆ itters…      ┆          ┆              ┆              ┆             ┆ split3,     │\n",
      "│              ┆              ┆          ┆              ┆              ┆             ┆ split4…     │\n",
      "│ cellular_mul ┆ /Users/snapp ┆ 1349158  ┆ 1349021      ┆ 376738       ┆ 329         ┆ split1,     │\n",
      "│ tilabel      ┆ i/frequent-h ┆          ┆              ┆              ┆             ┆ split2,     │\n",
      "│              ┆ itters…      ┆          ┆              ┆              ┆             ┆ split3,     │\n",
      "│              ┆              ┆          ┆              ┆              ┆             ┆ split4…     │\n",
      "└──────────────┴──────────────┴──────────┴──────────────┴──────────────┴─────────────┴─────────────┘\n",
      "\n",
      "Split counts per dataset/seed:\n",
      "shape: (60, 6)\n",
      "┌────────────────────────┬──────────────┬───────┬──────────┬──────────────────┬──────────────────┐\n",
      "│ dataset                ┆ split_column ┆ split ┆ num_rows ┆ unique_compounds ┆ unique_scaffolds │\n",
      "│ ---                    ┆ ---          ┆ ---   ┆ ---      ┆ ---              ┆ ---              │\n",
      "│ str                    ┆ str          ┆ str   ┆ i64      ┆ i64              ┆ i64              │\n",
      "╞════════════════════════╪══════════════╪═══════╪══════════╪══════════════════╪══════════════════╡\n",
      "│ biochemical_multilabel ┆ split1       ┆ test  ┆ 36782    ┆ 36782            ┆ 10139            │\n",
      "│ biochemical_multilabel ┆ split1       ┆ train ┆ 1695571  ┆ 1695459          ┆ 492390           │\n",
      "│ biochemical_multilabel ┆ split1       ┆ val   ┆ 211946   ┆ 211942           ┆ 49273            │\n",
      "│ biochemical_multilabel ┆ split2       ┆ test  ┆ 36837    ┆ 36837            ┆ 10523            │\n",
      "│ biochemical_multilabel ┆ split2       ┆ train ┆ 1695522  ┆ 1695408          ┆ 478585           │\n",
      "│ …                      ┆ …            ┆ …     ┆ …        ┆ …                ┆ …                │\n",
      "│ cellular_regression    ┆ split4       ┆ train ┆ 292295   ┆ 292279           ┆ 81515            │\n",
      "│ cellular_regression    ┆ split4       ┆ val   ┆ 36539    ┆ 36539            ┆ 10587            │\n",
      "│ cellular_regression    ┆ split5       ┆ test  ┆ 36540    ┆ 36540            ┆ 10937            │\n",
      "│ cellular_regression    ┆ split5       ┆ train ┆ 292294   ┆ 292286           ┆ 81448            │\n",
      "│ cellular_regression    ┆ split5       ┆ val   ┆ 36536    ┆ 36536            ┆ 10343            │\n",
      "└────────────────────────┴──────────────┴───────┴──────────┴──────────────────┴──────────────────┘\n",
      "\n",
      "Test split consistency (regression vs multitask):\n",
      "shape: (10, 7)\n",
      "┌──────────────┬─────────────┬─────────────┬─────────────┬─────────────┬─────────────┬─────────────┐\n",
      "│ assay_format ┆ split_colum ┆ regression_ ┆ multitask_c ┆ regression_ ┆ multitask_o ┆ test_sets_m │\n",
      "│ ---          ┆ n           ┆ count       ┆ ount        ┆ only        ┆ nly         ┆ atch        │\n",
      "│ str          ┆ ---         ┆ ---         ┆ ---         ┆ ---         ┆ ---         ┆ ---         │\n",
      "│              ┆ str         ┆ i64         ┆ i64         ┆ i64         ┆ i64         ┆ bool        │\n",
      "╞══════════════╪═════════════╪═════════════╪═════════════╪═════════════╪═════════════╪═════════════╡\n",
      "│ biochemical  ┆ split1      ┆ 36782       ┆ 36782       ┆ 0           ┆ 0           ┆ true        │\n",
      "│ biochemical  ┆ split2      ┆ 36837       ┆ 36837       ┆ 0           ┆ 0           ┆ true        │\n",
      "│ biochemical  ┆ split3      ┆ 35419       ┆ 35419       ┆ 0           ┆ 0           ┆ true        │\n",
      "│ biochemical  ┆ split4      ┆ 36832       ┆ 36832       ┆ 0           ┆ 0           ┆ true        │\n",
      "│ biochemical  ┆ split5      ┆ 36839       ┆ 36839       ┆ 0           ┆ 0           ┆ true        │\n",
      "│ cellular     ┆ split1      ┆ 36527       ┆ 36527       ┆ 0           ┆ 0           ┆ true        │\n",
      "│ cellular     ┆ split2      ┆ 36528       ┆ 36528       ┆ 0           ┆ 0           ┆ true        │\n",
      "│ cellular     ┆ split3      ┆ 36537       ┆ 36537       ┆ 0           ┆ 0           ┆ true        │\n",
      "│ cellular     ┆ split4      ┆ 36536       ┆ 36536       ┆ 0           ┆ 0           ┆ true        │\n",
      "│ cellular     ┆ split5      ┆ 36540       ┆ 36540       ┆ 0           ┆ 0           ┆ true        │\n",
      "└──────────────┴─────────────┴─────────────┴─────────────┴─────────────┴─────────────┴─────────────┘\n"
     ]
    }
   ],
   "source": [
    "processed_stats = []\n",
    "split_rows = []\n",
    "\n",
    "for dataset_name, path in processed_paths.items():\n",
    "    lf = pl.scan_parquet(path)\n",
    "    schema_names = lf.collect_schema().names()\n",
    "    split_cols = sorted([c for c in schema_names if c.startswith(\"split\")])\n",
    "    assay_cols = [c for c in schema_names if c.isdigit()]\n",
    "\n",
    "    base_counts = (\n",
    "        lf.select(\n",
    "            pl.len().alias(\"num_rows\"),\n",
    "            pl.col(\"compound_id\").n_unique().alias(\"unique_compounds\"),\n",
    "            pl.col(\"scaffold_smiles\").n_unique().alias(\"unique_scaffolds\"),\n",
    "        )\n",
    "        .collect()\n",
    "        .to_dicts()[0]\n",
    "    )\n",
    "\n",
    "    processed_stats.append(\n",
    "        {\n",
    "            \"dataset\": dataset_name,\n",
    "            \"path\": str(path),\n",
    "            \"num_rows\": base_counts[\"num_rows\"],\n",
    "            \"unique_compounds\": base_counts[\"unique_compounds\"],\n",
    "            \"unique_scaffolds\": base_counts[\"unique_scaffolds\"],\n",
    "            \"num_assay_tasks\": len(assay_cols),\n",
    "            \"split_columns\": \", \".join(split_cols),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    for split_col in split_cols:\n",
    "        counts = (\n",
    "            lf.group_by(pl.col(split_col))\n",
    "            .agg(\n",
    "                pl.len().alias(\"num_rows\"),\n",
    "                pl.col(\"compound_id\").n_unique().alias(\"unique_compounds\"),\n",
    "                pl.col(\"scaffold_smiles\").n_unique().alias(\"unique_scaffolds\"),\n",
    "            )\n",
    "            .collect()\n",
    "        )\n",
    "        for row in counts.to_dicts():\n",
    "            split_rows.append(\n",
    "                {\n",
    "                    \"dataset\": dataset_name,\n",
    "                    \"split_column\": split_col,\n",
    "                    \"split\": row[split_col],\n",
    "                    \"num_rows\": row[\"num_rows\"],\n",
    "                    \"unique_compounds\": row[\"unique_compounds\"],\n",
    "                    \"unique_scaffolds\": row[\"unique_scaffolds\"],\n",
    "                }\n",
    "            )\n",
    "\n",
    "processed_summary = pl.DataFrame(processed_stats)\n",
    "split_value_summary = pl.DataFrame(split_rows)\n",
    "\n",
    "print(\"Processed dataset overview:\")\n",
    "print(processed_summary)\n",
    "\n",
    "print()\n",
    "print(\"Split counts per dataset/seed:\")\n",
    "print(split_value_summary.sort([\"dataset\", \"split_column\", \"split\"]))\n",
    "\n",
    "# Check that regression and multitask test sets match for each seed.\n",
    "split_pairs = {\n",
    "    \"biochemical\": (\"biochemical_regression\", \"biochemical_multilabel\"),\n",
    "    \"cellular\": (\"cellular_regression\", \"cellular_multilabel\"),\n",
    "}\n",
    "\n",
    "test_checks = []\n",
    "for assay_format, (reg_key, mt_key) in split_pairs.items():\n",
    "    reg_path = processed_paths[reg_key]\n",
    "    mt_path = processed_paths[mt_key]\n",
    "\n",
    "    reg_schema = pl.scan_parquet(reg_path).collect_schema().names()\n",
    "    mt_schema = pl.scan_parquet(mt_path).collect_schema().names()\n",
    "\n",
    "    reg_split_cols = sorted([c for c in reg_schema if c.startswith(\"split\")])\n",
    "    mt_split_cols = sorted([c for c in mt_schema if c.startswith(\"split\")])\n",
    "\n",
    "    if reg_split_cols != mt_split_cols:\n",
    "        raise ValueError(\n",
    "            f\"Split columns mismatch for {assay_format}: {reg_split_cols} vs {mt_split_cols}\"\n",
    "        )\n",
    "\n",
    "    for split_col in reg_split_cols:\n",
    "        reg_test = (\n",
    "            pl.scan_parquet(reg_path)\n",
    "            .filter(pl.col(split_col) == \"test\")\n",
    "            .select(\"compound_id\")\n",
    "            .unique()\n",
    "        )\n",
    "        mt_test = (\n",
    "            pl.scan_parquet(mt_path)\n",
    "            .filter(pl.col(split_col) == \"test\")\n",
    "            .select(\"compound_id\")\n",
    "            .unique()\n",
    "        )\n",
    "\n",
    "        reg_count = reg_test.select(pl.len()).collect().item()\n",
    "        mt_count = mt_test.select(pl.len()).collect().item()\n",
    "        reg_not_mt = (\n",
    "            reg_test.join(mt_test, on=\"compound_id\", how=\"anti\")\n",
    "            .select(pl.len())\n",
    "            .collect()\n",
    "            .item()\n",
    "        )\n",
    "        mt_not_reg = (\n",
    "            mt_test.join(reg_test, on=\"compound_id\", how=\"anti\")\n",
    "            .select(pl.len())\n",
    "            .collect()\n",
    "            .item()\n",
    "        )\n",
    "\n",
    "        test_checks.append(\n",
    "            {\n",
    "                \"assay_format\": assay_format,\n",
    "                \"split_column\": split_col,\n",
    "                \"regression_count\": reg_count,\n",
    "                \"multitask_count\": mt_count,\n",
    "                \"regression_only\": reg_not_mt,\n",
    "                \"multitask_only\": mt_not_reg,\n",
    "                \"test_sets_match\": reg_not_mt == 0 and mt_not_reg == 0 and reg_count == mt_count,\n",
    "            }\n",
    "        )\n",
    "\n",
    "test_split_consistency = pl.DataFrame(test_checks)\n",
    "print()\n",
    "print(\"Test split consistency (regression vs multitask):\")\n",
    "print(test_split_consistency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52500037",
   "metadata": {},
   "source": [
    "## 6. Structure-cleaning summary\n",
    "\n",
    "Use the precomputed `assay_cleaning_stats.json` emitted by the cleaning CLI instead of re-running RDKit in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87d1044b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structure cleaning summary (precomputed):\n",
      "Drop reasons (unique SMILES):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (6, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>reason</th><th>count</th><th>fraction_pct</th></tr><tr><td>str</td><td>i64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;retained&quot;</td><td>2549457</td><td>98.489011</td></tr><tr><td>&quot;molecular_weight_filter&quot;</td><td>36915</td><td>1.426077</td></tr><tr><td>&quot;forbidden_atom&quot;</td><td>2156</td><td>0.083289</td></tr><tr><td>&quot;canonical_validation_failed&quot;</td><td>34</td><td>0.001313</td></tr><tr><td>&quot;invalid_smiles&quot;</td><td>7</td><td>0.00027</td></tr><tr><td>&quot;uncharger_error&quot;</td><td>1</td><td>0.000039</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (6, 3)\n",
       "┌─────────────────────────────┬─────────┬──────────────┐\n",
       "│ reason                      ┆ count   ┆ fraction_pct │\n",
       "│ ---                         ┆ ---     ┆ ---          │\n",
       "│ str                         ┆ i64     ┆ f64          │\n",
       "╞═════════════════════════════╪═════════╪══════════════╡\n",
       "│ retained                    ┆ 2549457 ┆ 98.489011    │\n",
       "│ molecular_weight_filter     ┆ 36915   ┆ 1.426077     │\n",
       "│ forbidden_atom              ┆ 2156    ┆ 0.083289     │\n",
       "│ canonical_validation_failed ┆ 34      ┆ 0.001313     │\n",
       "│ invalid_smiles              ┆ 7       ┆ 0.00027      │\n",
       "│ uncharger_error             ┆ 1       ┆ 0.000039     │\n",
       "└─────────────────────────────┴─────────┴──────────────┘"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load structure-cleaning stats produced during assay-cleaning\n",
    "if not assay_cleaning_stats_path.is_file():\n",
    "    raise FileNotFoundError(f\"Missing stats file at {assay_cleaning_stats_path}\")\n",
    "\n",
    "stats = json.loads(assay_cleaning_stats_path.read_text())\n",
    "structure_stats = stats.get(\"structure_cleaning\", {})\n",
    "\n",
    "structure_summary = pl.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"unique_smiles\": structure_stats.get(\"unique_smiles\"),\n",
    "            \"valid_canonical_smiles\": structure_stats.get(\"valid_canonical_smiles\"),\n",
    "            \"dropped\": structure_stats.get(\"dropped\"),\n",
    "            \"skip_tautomers\": structure_stats.get(\"skip_tautomers\"),\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "reason_rows = [\n",
    "    {\"reason\": reason, \"count\": count}\n",
    "    for reason, count in structure_stats.get(\"drop_reasons\", {}).items()\n",
    "]\n",
    "\n",
    "reason_summary = (\n",
    "    pl.DataFrame(reason_rows)\n",
    "    .sort(\"count\", descending=True)\n",
    "    .with_columns(\n",
    "        (pl.col(\"count\") / structure_stats.get(\"unique_smiles\", 1) * 100).alias(\"fraction_pct\")\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"Structure cleaning summary (precomputed):\")\n",
    "structure_summary\n",
    "\n",
    "print(\"Drop reasons (unique SMILES):\")\n",
    "reason_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36b0f88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "frequent-hitters",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
